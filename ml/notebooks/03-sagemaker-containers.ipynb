{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.215.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import boto3\n",
    "import botocore\n",
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "import sagemaker\n",
    "from time import gmtime, strftime, sleep\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sagemaker.experiments.run import Run, load_run\n",
    "\n",
    "sagemaker.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "boto_session = boto3.Session()\n",
    "region = boto_session.region_name\n",
    "print(f\"Region--{region}\")\n",
    "sm_role = sagemaker.get_execution_role()\n",
    "print(f\"Sagemaker Role--{sm_role}\")\n",
    "sagemaker_session = sagemaker.Session()\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "print(f\"Default bucket--{default_bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAGEMAKER CONTAINERS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "CREATE SageMaker processing and training jobs\n",
    "In this step you move data processing and model training into SageMaker Docker containers and use SageMaker Python SDK to interact with SageMaker.\n",
    "\n",
    "\n",
    "\n",
    "* **SageMaker** makes use of Docker containers to enable developers to process data, train and deploy models. \n",
    "\n",
    "* **SageMaker** also provides pre-build containers with popular data processing frameworks and ML algorithms. All SageMaker built-in algorithms are delivered as Docker containers.\n",
    "\n",
    "* **Containers** allow developers and data scientists to package software into standardized units that run consistently on any platform that supports Docker. \n",
    "\n",
    "* **Containers** ensure that code, runtime, system tools, system libraries, and settings are all in the same place, isolating them from the execution environment. It guarantees a consistent runtime experience regardless of where a container is being run.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process data in sagemaker processing jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process data in SageMaker processing job\n",
    "\n",
    "* Use **SageMaker Processing** by simply providing a Python data preprocessing script and choosing a SageMaker SDK processor class. \n",
    "You must upload the input data to S3 and specify an S3 location for output data. \n",
    "\n",
    "* **SageMaker Processing** automatically loads the input data from S3 and uploads transformed data back to S3 when the job is complete. \n",
    "\n",
    "* The processing container image can either be an Amazon SageMaker built-in image or a custom image that you provide. \n",
    "\n",
    "* The underlying infrastructure for a Processing job is fully managed by Amazon SageMaker. \n",
    "\n",
    "* Cluster resources are provisioned for the duration of your job, and cleaned up when a job completes.\n",
    "\n",
    "* Your input data must be stored in an Amazon S3 bucket. Alternatively, you can use Amazon Athena or Amazon Redshift as input sources.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'features': ['dteday', 'season', 'hr', 'holiday', 'weekday', 'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed', 'casual', 'registered', 'yr', 'mnth'], 'holiday_mappings': {'No': 1, 'Yes': 0}, 'hr_mappings': {'10am': 9, '10pm': 8, '11am': 11, '11pm': 7, '12am': 5, '12pm': 17, '1am': 4, '1pm': 16, '2am': 3, '2pm': 15, '3am': 1, '3pm': 18, '4am': 0, '4pm': 19, '5am': 2, '5pm': 23, '6am': 6, '6pm': 22, '7am': 12, '7pm': 20, '8am': 21, '8pm': 14, '9am': 13, '9pm': 10}, 'mnth_mappings': {'April': 5, 'August': 11, 'December': 2, 'February': 1, 'January': 0, 'July': 10, 'June': 9, 'March': 3, 'May': 7, 'November': 4, 'October': 6, 'September': 8}, 's3-bucket': {'bucket_name': 'sagemaker-us-east-1-644383320443', 'bucket_prefix': 'siemens-poc/', 'training_file_key': 'siemens-poc/bike-sharing-dataset.csv'}, 'sagemaker': {'domain_id': 'd-zjfao8azi0ng', 'region': 'us-east-1', 'role': 'arn:aws:iam::644383320443:role/service-role/AmazonSageMaker-ExecutionRole-20240109T220483'}, 'season_mappings': {'fall': 3, 'spring': 0, 'summer': 2, 'winter': 1}, 'target': 'cnt', 'weathersit_mappings': {'Clear': 3, 'Heavy Rain': 0, 'Light Rain': 1, 'Mist': 2}, 'workingday_mappings': {'No': 0, 'Yes': 1}, 'yr_mappings': {2011: 0, 2012: 1}}\n"
     ]
    }
   ],
   "source": [
    "# import config\n",
    "import os\n",
    "import yaml\n",
    "with open(os.path.abspath(os.path.join(os.pardir,\"config.yml\")),\"r\") as f:\n",
    "    config = yaml.load(f,Loader=yaml.FullLoader)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 ls {config['s3-bucket']['bucket_name']}/{config['s3-bucket']['bucket_prefix']} --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write preprocessing script \n",
    "> for pre-processing done on the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../scripts/preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../scripts/preprocessing.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "# Treating 'yr' column as Ordinal categorical variable, assign higher value to 2012\n",
    "yr_mapping = {2011: 0, 2012: 1}\n",
    "# Treat 'mnth' column as Ordinal categorical variable, and assign values accordingly\n",
    "mnth_mapping = {'January': 0, 'February': 1, 'December': 2, 'March': 3, 'November': 4, 'April': 5,\n",
    "                'October': 6, 'May': 7, 'September': 8, 'June': 9, 'July': 10, 'August': 11}\n",
    "# Treat 'season' column as Ordinal categorical variable, and assign values accordingly\n",
    "season_mapping = {'spring': 0, 'winter': 1, 'summer': 2, 'fall': 3}\n",
    "# Map weather situation\n",
    "weather_mapping = {'Heavy Rain': 0, 'Light Rain': 1, 'Mist': 2, 'Clear': 3}\n",
    "# Map holiday\n",
    "holiday_mapping = {'Yes': 0, 'No': 1}\n",
    "# Map workingday\n",
    "workingday_mapping = {'No': 0, 'Yes': 1}\n",
    "# Map hour\n",
    "hour_mapping = {'4am': 0, '3am': 1, '5am': 2, '2am': 3, '1am': 4, '12am': 5, '6am': 6, '11pm': 7, '10pm': 8,\n",
    "                '10am': 9, '9pm': 10, '11am': 11, '7am': 12, '9am': 13, '8pm': 14, '2pm': 15, '1pm': 16,\n",
    "                '12pm': 17, '3pm': 18, '4pm': 19, '7pm': 20, '8am': 21, '6pm': 22, '5pm': 23}\n",
    "\n",
    "\n",
    "# find numerical and categorical variables\n",
    "def get_feature_categories(df):\n",
    "    unused_colms = ['dteday', 'casual', 'registered']   # unused columns will be removed at later stage\n",
    "    target_col = ['cnt']\n",
    "\n",
    "    numerical_features = []\n",
    "    categorical_features = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col not in target_col + unused_colms:\n",
    "            if df[col].dtypes == 'float64':\n",
    "                numerical_features.append(col)\n",
    "            else:\n",
    "                categorical_features.append(col)\n",
    "    print('Number of numerical variables: {}'.format(len(numerical_features)),\":\" , numerical_features)\n",
    "    print('Number of categorical variables: {}'.format(len(categorical_features)),\":\" , categorical_features)\n",
    "    return numerical_features , categorical_features , unused_colms\n",
    "\n",
    "\n",
    " # Working on `dteday` column to extract year and month\n",
    "def get_year_and_month(dataframe):\n",
    "    df = dataframe.copy()\n",
    "    # convert 'dteday' column to Datetime datatype\n",
    "    df['dteday'] = pd.to_datetime(df['dteday'], format='%Y-%m-%d')\n",
    "    # Add new features 'yr' and 'mnth\n",
    "    df['yr'] = df['dteday'].dt.year\n",
    "    df['mnth'] = df['dteday'].dt.month_name()\n",
    "    print(\"Added yr and month variables to the dataframe--\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# Function to impute weekday by extracting day name from the date column\n",
    "\n",
    "def impute_weekday(dataframe):\n",
    "    df = dataframe.copy()\n",
    "    wkday_null_idx = df[df['weekday'].isnull() == True].index\n",
    "    # print(len(wkday_null_idx))\n",
    "    df.loc[wkday_null_idx, 'weekday'] = df.loc[wkday_null_idx, 'dteday'].dt.day_name().apply(lambda x: x[:3])\n",
    "    print(\"imputed weekday in dataframe--\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# Function to handle outliers for a single column\n",
    "\n",
    "def handle_outliers(dataframe, colm):\n",
    "    df = dataframe.copy()\n",
    "    q1 = df.describe()[colm].loc['25%']\n",
    "    q3 = df.describe()[colm].loc['75%']\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - (1.5 * iqr)\n",
    "    upper_bound = q3 + (1.5 * iqr)\n",
    "    for i in df.index:\n",
    "        if df.loc[i,colm] > upper_bound:\n",
    "            df.loc[i,colm]= upper_bound\n",
    "        if df.loc[i,colm] < lower_bound:\n",
    "            df.loc[i,colm]= lower_bound\n",
    "    print(f\"outliers handled in column--{colm}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# Treating 'weekday' column as a Nominal categorical variable, perform one-hot encoding\n",
    "from sklearn.preprocessing import  OneHotEncoder\n",
    "# build encoder\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "## Function for pre-processing the dataset\n",
    "\n",
    "def pre_process(dataframe):\n",
    "    df = dataframe.copy()\n",
    "    df = get_year_and_month(df)\n",
    "    df = impute_weekday(df)\n",
    "    df['weathersit'].fillna('Clear', inplace=True)\n",
    "    numerical_features , categorical_features , unused_colms = get_feature_categories(df)\n",
    "    for col in numerical_features:\n",
    "        df = handle_outliers(df, col)\n",
    "    df['yr'] = df['yr'].apply(lambda x: yr_mapping[x])\n",
    "    df['mnth'] = df['mnth'].apply(lambda x: mnth_mapping[x])\n",
    "    df['season'] = df['season'].apply(lambda x: season_mapping[x])\n",
    "    df['weathersit'] = df['weathersit'].apply(lambda x: weather_mapping[x])\n",
    "    df['holiday'] = df['holiday'].apply(lambda x: holiday_mapping[x])\n",
    "    df['workingday'] = df['workingday'].apply(lambda x: workingday_mapping[x])\n",
    "    df['hr'] = df['hr'].apply(lambda x: hour_mapping[x])\n",
    "    encoder.fit(df[['weekday']])\n",
    "    enc_wkday_features = encoder.get_feature_names_out(['weekday'])\n",
    "    encoded_weekday = encoder.transform(df[['weekday']]).toarray()\n",
    "    df[enc_wkday_features] = encoded_weekday\n",
    "    # drop not required columns\n",
    "    unused_colms.append('weekday')\n",
    "    df.drop(labels = unused_colms, axis = 1, inplace = True)\n",
    "    print(\"preprocessing done !\")\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _parse_args():\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    # Data, model, and output directories\n",
    "    # model_dir is always passed in from SageMaker. By default this is a S3 path under the default bucket.\n",
    "    parser.add_argument('--filepath', type=str, default='/opt/ml/processing/input/')\n",
    "    parser.add_argument('--filename', type=str, default='bits-webminar-june-24/bike-sharing-dataset.csv')\n",
    "    parser.add_argument('--outputpath', type=str, default='/opt/ml/processing/output/')\n",
    "    \n",
    "    return parser.parse_known_args()\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    # Process arguments\n",
    "    args, _ = _parse_args()\n",
    "    \n",
    "    target_col = \"cnt\"\n",
    "    \n",
    "    # Load data\n",
    "    df_data = pd.read_csv(os.path.join(args.filepath, args.filename))\n",
    "    try:\n",
    "        df_data.drop(['Unnamed: 0'],axis=1 , inplace=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Exception occured in dropping column--unnamed: 0-->{e}\")\n",
    "    processed_data = pre_process(df_data)\n",
    "\n",
    "    # Shuffle and splitting dataset\n",
    "    train_data, validation_data, test_data = np.split(\n",
    "    processed_data.sample(frac=1, random_state=1729),\n",
    "    [int(0.7 * len(processed_data)), int(0.9 * len(processed_data))],)\n",
    "\n",
    "    print(f\"Data split > train:{train_data.shape} | validation:{validation_data.shape} | test:{test_data.shape}\")\n",
    "\n",
    "    \n",
    "    # Save datasets locally\n",
    "    train_data.to_csv(os.path.join(args.outputpath, 'train/train.csv'), index=False, header=True)\n",
    "    validation_data.to_csv(os.path.join(args.outputpath, 'validation/validation.csv'), index=False, header=True)\n",
    "    test_data[target_col].to_csv(os.path.join(args.outputpath, 'test/test_y.csv'), index=False, header=True)\n",
    "    test_data.drop([target_col], axis=1).to_csv(os.path.join(args.outputpath, 'test/test_x.csv'), index=False, header=True)\n",
    "    \n",
    "    # Save the baseline dataset for model monitoring\n",
    "    processed_data.drop([target_col], axis=1).to_csv(os.path.join(args.outputpath, 'baseline/baseline.csv'), index=True, header=False)\n",
    "    \n",
    "    print(\"## Processing complete. Exiting.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set s3 paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_default_bucket():\n",
    "    boto_session = boto3.Session()\n",
    "    # region = boto_session.region_name\n",
    "    # print(f\"Region--{region}\")\n",
    "    # sm_role = sagemaker.get_execution_role()\n",
    "    # print(f\"Sagemaker Role--{sm_role}\")\n",
    "    sagemaker_session = sagemaker.Session()\n",
    "    default_bucket = sagemaker_session.default_bucket()\n",
    "    print(f\"Default bucket--{default_bucket}\")\n",
    "    return default_bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default bucket--sagemaker-eu-north-1-058264393695\n",
      "sagemaker-eu-north-1-058264393695\n"
     ]
    }
   ],
   "source": [
    "PREFIX = 'bits-webminar-june-24/'\n",
    "DEFAULT_BUCKET = get_default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# bucket_name = config['s3-bucket']['bucket_name']\n",
    "# bucket_prefix = f'{config[\"s3-bucket\"][\"bucket_prefix\"]}conatiner-jobs'\n",
    "# print(f\"bucket_prefix for containers--> {DEFAULT_BUCKET}\")\n",
    "# input_s3_url = f's3://{bucket_name}/{config[\"s3-bucket\"][\"training_file_key\"]}'\n",
    "# print(f\"input_s3_url--> {input_s3_url}\")\n",
    "\n",
    "# train_s3_url = f\"s3://{bucket_name}/{bucket_prefix}/train\"\n",
    "# print(f\"train_s3_url--> {train_s3_url}\")\n",
    "\n",
    "# validation_s3_url = f\"s3://{bucket_name}/{bucket_prefix}/validation\"\n",
    "# print(f\"validation_s3_url--> {validation_s3_url}\")\n",
    "\n",
    "# test_s3_url = f\"s3://{bucket_name}/{bucket_prefix}/test\"\n",
    "# print(f\"test_s3_url--> {test_s3_url}\")\n",
    "\n",
    "# baseline_s3_url = f\"s3://{bucket_name}/{bucket_prefix}/baseline\"\n",
    "# print(f\"baseline_s3_url--> {baseline_s3_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_s3_url--> s3://sagemaker-eu-north-1-058264393695/bits-webminar-june-24/bike-sharing-dataset.csv\n",
      "train_s3_url--> s3://sagemaker-eu-north-1-058264393695/bits-webminar-june-24/train_data.csv\n",
      "test_s3_url--> s3://sagemaker-eu-north-1-058264393695/bits-webminar-june-24/test_data.csv\n",
      "test_s3_url--> s3://sagemaker-eu-north-1-058264393695/bits-webminar-june-24/test_data.csv\n",
      "baseline_s3_url--> s3://sagemaker-eu-north-1-058264393695/bits-webminar-june-24//baseline\n"
     ]
    }
   ],
   "source": [
    "input_s3_url ='s3://sagemaker-eu-north-1-058264393695/bits-webminar-june-24/bike-sharing-dataset.csv'\n",
    "print(f\"input_s3_url--> {input_s3_url}\")\n",
    "train_s3_url ='s3://sagemaker-eu-north-1-058264393695/bits-webminar-june-24/train_data.csv'\n",
    "print(f\"train_s3_url--> {train_s3_url}\")\n",
    "test_s3_url ='s3://sagemaker-eu-north-1-058264393695/bits-webminar-june-24/test_data.csv'\n",
    "print(f\"test_s3_url--> {test_s3_url}\")\n",
    "validation_s3_url ='s3://sagemaker-eu-north-1-058264393695/bits-webminar-june-24/validation_data.csv'\n",
    "print(f\"test_s3_url--> {test_s3_url}\")\n",
    "baseline_s3_url = f\"s3://{DEFAULT_BUCKET}/{PREFIX}/baseline\"\n",
    "print(f\"baseline_s3_url--> {baseline_s3_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "framework_version = \"0.23-1\"\n",
    "processing_instance_type = \"ml.t3.medium\"\n",
    "processing_instance_count = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create an experiment run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiment_name = \"bits-webminar-june-24-21-06-2024-15-11-46\"\n",
    "# using the existing experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/bits-webminar-june-24/ml\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "root_dir = Path('../scripts').resolve().parents[0] \n",
    "print(root_dir)\n",
    "sys.path.append(str(root_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'21-06-2024-15-22-58'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scripts.utils as utils\n",
    "run_suffix = utils.get_current_ist().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "run_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "sm_client = sagemaker_session.sagemaker_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_name = f\"container-processing-{run_suffix}\"\n",
    "\n",
    "with Run(experiment_name=experiment_name,\n",
    "         run_name=run_name,\n",
    "         run_display_name=\"container-processing\",\n",
    "         sagemaker_session=sagemaker_session\n",
    "        ) as run:\n",
    "    run.log_parameters(\n",
    "        {\n",
    "            \"train\": 0.7,\n",
    "            \"validate\": 0.2,\n",
    "            \"test\": 0.1\n",
    "        }\n",
    "    )\n",
    "   \n",
    "    experiment_config = run.experiment_config\n",
    "    # time.sleep(8) # wait until resource tags are propagated to the run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create a sklearn processor --IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sagemaker Role--arn:aws:iam::058264393695:role/service-role/AmazonSageMaker-ExecutionRole-20240621T001438\n"
     ]
    }
   ],
   "source": [
    "# sm_role = config['sagemaker']['role']\n",
    "# sm_role\n",
    "\n",
    "sm_role = sagemaker.get_execution_role()\n",
    "print(f\"Sagemaker Role--{sm_role}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n"
     ]
    }
   ],
   "source": [
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    role=sm_role,\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count, \n",
    "    base_job_name='container-processing',\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define processing job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processing_inputs = [\n",
    "        ProcessingInput(\n",
    "            source=input_s3_url, \n",
    "            destination=\"/opt/ml/processing/input\",\n",
    "            s3_input_mode=\"File\",\n",
    "            s3_data_distribution_type=\"ShardedByS3Key\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "processing_outputs = [\n",
    "        ProcessingOutput(\n",
    "            output_name=\"train_data\", \n",
    "            source=\"/opt/ml/processing/output/train\",\n",
    "            destination=train_s3_url,\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"validation_data\", \n",
    "            source=\"/opt/ml/processing/output/validation\", \n",
    "            destination=validation_s3_url\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"test_data\", \n",
    "            source=\"/opt/ml/processing/output/test\", \n",
    "            destination=test_s3_url\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"baseline_data\", \n",
    "            source=\"/opt/ml/processing/output/baseline\", \n",
    "            destination=baseline_s3_url\n",
    "        ),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start the sagemaker processing job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name container-processing-2024-06-21-11-24-07-988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........................................................................\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/ml/processing/input/code/preprocessing.py\", line 140, in <module>\n",
      "    df_data = pd.read_csv(os.path.join(args.filepath, args.filename))\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/pandas/io/parsers.py\", line 686, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/pandas/io/parsers.py\", line 452, in _read\n",
      "    parser = TextFileReader(fp_or_buf, **kwds)\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/pandas/io/parsers.py\", line 946, in __init__\n",
      "    self._make_engine(self.engine)\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/pandas/io/parsers.py\", line 1178, in _make_engine\n",
      "    self._engine = CParserWrapper(self.f, **self.options)\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/pandas/io/parsers.py\", line 2008, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "  File \"pandas/_libs/parsers.pyx\", line 382, in pandas._libs.parsers.TextReader.__cinit__\n",
      "  File \"pandas/_libs/parsers.pyx\", line 674, in pandas._libs.parsers.TextReader._setup_parser_source\u001b[0m\n",
      "\u001b[34mFileNotFoundError: [Errno 2] No such file or directory: '/opt/ml/processing/input/bits-webminar-june-24/bike-sharing-dataset.csv'\u001b[0m\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Processing job container-processing-2024-06-21-11-24-07-988: Failed. Reason: AlgorithmError: See job logs for more information",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43msklearn_processor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessing_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessing_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../scripts/preprocessing.py\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexperiment_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# arguments = ['arg1', 'arg2'],\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m botocore\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mresponse[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccessDeniedException\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:346\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/processing.py:688\u001b[0m, in \u001b[0;36mScriptProcessor.run\u001b[0;34m(self, code, inputs, outputs, arguments, wait, logs, job_name, experiment_config, kms_key)\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjobs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_job)\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m--> 688\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatest_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/processing.py:1113\u001b[0m, in \u001b[0;36mProcessingJob.wait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Waits for the processing job to complete.\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \n\u001b[1;32m   1108\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;124;03m    logs (bool): Whether to show the logs produced by the job (default: True).\u001b[39;00m\n\u001b[1;32m   1110\u001b[0m \n\u001b[1;32m   1111\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logs:\n\u001b[0;32m-> 1113\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogs_for_processing_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session\u001b[38;5;241m.\u001b[39mwait_for_processing_job(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_name)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/session.py:5836\u001b[0m, in \u001b[0;36mSession.logs_for_processing_job\u001b[0;34m(self, job_name, wait, poll)\u001b[0m\n\u001b[1;32m   5833\u001b[0m             state \u001b[38;5;241m=\u001b[39m LogState\u001b[38;5;241m.\u001b[39mJOB_COMPLETE\n\u001b[1;32m   5835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 5836\u001b[0m     \u001b[43m_check_job_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mProcessingJobStatus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5837\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dot:\n\u001b[1;32m   5838\u001b[0m         \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/session.py:8042\u001b[0m, in \u001b[0;36m_check_job_status\u001b[0;34m(job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   8036\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCapacityError\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(reason):\n\u001b[1;32m   8037\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mCapacityError(\n\u001b[1;32m   8038\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   8039\u001b[0m         allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   8040\u001b[0m         actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   8041\u001b[0m     )\n\u001b[0;32m-> 8042\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mUnexpectedStatusException(\n\u001b[1;32m   8043\u001b[0m     message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   8044\u001b[0m     allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   8045\u001b[0m     actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   8046\u001b[0m )\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Processing job container-processing-2024-06-21-11-24-07-988: Failed. Reason: AlgorithmError: See job logs for more information"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sklearn_processor.run(\n",
    "        inputs=processing_inputs,\n",
    "        outputs=processing_outputs,\n",
    "        code='../scripts/preprocessing.py',\n",
    "        wait=True,\n",
    "        experiment_config=experiment_config,\n",
    "        # arguments = ['arg1', 'arg2'],\n",
    "    )\n",
    "except botocore.exceptions.ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'AccessDeniedException':\n",
    "        print(f\"Ignore AccessDeniedException: {e.response['Error']['Message']} because of the slow resource tag auto propagation\")\n",
    "    else:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training in SageMaker training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.5-1\n"
     ]
    }
   ],
   "source": [
    "# get training container uri\n",
    "# region = config['sagemaker']['region']\n",
    "training_image = sagemaker.image_uris.retrieve(\"xgboost\", region=region, version=\"1.5-1\")\n",
    "print(training_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-644383320443/siemens-poc/training-output'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_instance_count = 1\n",
    "train_instance_type = \"ml.m5.xlarge\"\n",
    "\n",
    "# Define where the training job stores the model artifact\n",
    "output_s3_url = f\"s3://{config['s3-bucket']['bucket_name']}/{config['s3-bucket']['bucket_prefix']}training-output\"\n",
    "output_s3_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an XGBoost estimator object\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=training_image,  # XGBoost algorithm container\n",
    "    instance_type=train_instance_type,  \n",
    "    instance_count=train_instance_count,  \n",
    "    role=sm_role,  \n",
    "    max_run=20 * 60,  # Maximum allowed active runtime\n",
    "    output_path=output_s3_url, # S3 location \n",
    "    sagemaker_session=sagemaker_session, # Session object  manages interactions with SageMaker API and AWS services\n",
    "    base_job_name=\"xgboost-training\", # Prefix for training job name\n",
    ")\n",
    "\n",
    "# define its hyperparameters\n",
    "estimator.set_hyperparameters(\n",
    "    num_round=150, # the number of rounds to run the training\n",
    "    max_depth=3, # maximum depth of a tree\n",
    "    eta=0.5, # step size shrinkage used in updates to prevent overfitting\n",
    "    alpha=2.5, # L1 regularization term on weights\n",
    "    objective=\"reg:squarederror\",\n",
    "    eval_metric=\"rmse\", # evaluation metrics for validation data\n",
    "    subsample=0.8, # subsample ratio of the training instance\n",
    "    colsample_bytree=0.8, # subsample ratio of columns when constructing each tree\n",
    "    min_child_weight=3, # minimum sum of instance weight (hessian) needed in a child\n",
    "    early_stopping_rounds=10, # the model trains until the validation score stops improving\n",
    "    verbosity=1, # verbosity of printing messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = sagemaker.inputs.TrainingInput(train_s3_url, content_type='csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(validation_s3_url, content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_inputs = {'train': s3_input_train, 'validation': s3_input_validation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_suffix--16-01-2024-00-57-28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: xgboost-training-2024-01-15-19-27-29-687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-01-15 19:27:30 Starting - Starting the training job..\n",
      "2024-01-15 19:27:45 Starting - Preparing the instances for training..............\n",
      "2024-01-15 19:29:04 Downloading - Downloading input data........\n",
      "2024-01-15 19:29:50 Downloading - Downloading the training image.\n",
      "2024-01-15 19:30:00 Training - Training image download completed. Training in progress....\n",
      "2024-01-15 19:30:20 Uploading - Uploading generated training model...\n",
      "2024-01-15 19:30:37 Completed - Training job completed\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    run_suffix = utils.get_current_ist().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "    print(f\"run_suffix--{run_suffix}\")\n",
    "    run_name = f\"container-training-{run_suffix}\"\n",
    "\n",
    "    with Run(experiment_name=experiment_name,\n",
    "             run_name=run_name,\n",
    "             run_display_name=\"container-training\",\n",
    "             sagemaker_session=sagemaker_session\n",
    "            ) as run:\n",
    "        \n",
    "        estimator.fit(\n",
    "            training_inputs,\n",
    "            wait=True,\n",
    "            logs=False,\n",
    "        ) \n",
    "except botocore.exceptions.ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'AccessDeniedException':\n",
    "        print(f\"Ignore AccessDeniedException: {e.response['Error']['Message']} because of the slow resource tag auto propagation\")\n",
    "    else:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# output model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if estimator._current_job_name:\n",
    "    training_job_name = estimator._current_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xgboost-training-2024-01-15-19-27-29-687'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.36, Validate RMSE: 0.40\n"
     ]
    }
   ],
   "source": [
    "metrics = None\n",
    "while not metrics:\n",
    "    metrics = sm_client.describe_training_job(\n",
    "        TrainingJobName=training_job_name\n",
    "        ).get(\"FinalMetricDataList\")\n",
    "\n",
    "    if not metrics:\n",
    "        print(f\"Training job {training_job_name} hasn't finished yet!\")\n",
    "        time.sleep(10)\n",
    "\n",
    "train_rmse = float([m['Value'] for m in metrics if m['MetricName'] == 'train:rmse'][0])\n",
    "validate_rmse = float([m['Value'] for m in metrics if m['MetricName'] == 'validation:rmse'][0])\n",
    "\n",
    "print(f\"Train RMSE: {train_rmse:.2f}, Validate RMSE: {validate_rmse:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-644383320443/siemens-poc/training-output/xgboost-training-2024-01-15-19-27-29-687/output/model.tar.gz'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the S3 path to the model artifact:\n",
    "estimator.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-644383320443/siemens-poc/data-capture'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destination_s3_uri=f\"s3://{config['s3-bucket']['bucket_name']}/{config['s3-bucket']['bucket_prefix']}data-capture\"\n",
    "destination_s3_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate model -- deploy endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: xgboost-training-2024-01-15-20-24-05-916\n",
      "INFO:sagemaker:Creating endpoint-config with name siemens-poc-xgboost-endpoint-15-20-24-05\n",
      "INFO:sagemaker:Creating endpoint with name siemens-poc-xgboost-endpoint-15-20-24-05\n"
     ]
    }
   ],
   "source": [
    "# Real-time endpoint\n",
    "from time import gmtime\n",
    "endpoint_name = f\"siemens-poc-xgboost-endpoint-{strftime('%d-%H-%M-%S', gmtime())}\"\n",
    "\n",
    "try:\n",
    "    predictor = estimator.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type=\"ml.m5.xlarge\",\n",
    "        wait=False,  \n",
    "        # data capture here, for experiment with monitoring:\n",
    "        data_capture_config=sagemaker.model_monitor.DataCaptureConfig(\n",
    "            enable_capture=True,\n",
    "            sampling_percentage=100,\n",
    "            destination_s3_uri=f\"s3://{config['s3-bucket']['bucket_name']}/{config['s3-bucket']['bucket_prefix']}data-capture\",\n",
    "        ),\n",
    "        endpoint_name=endpoint_name,\n",
    "        serializer=sagemaker.serializers.CSVSerializer(),\n",
    "        deserializer=sagemaker.deserializers.CSVDeserializer(),\n",
    "    )\n",
    "except botocore.exceptions.ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'AccessDeniedException':\n",
    "        print(f\"Ignore AccessDeniedException: {e.response['Error']['Message']} because of the slow resource tag auto propagation\")\n",
    "        predictor = sagemaker.predictor.Predictor(endpoint_name=endpoint_name,\n",
    "                                                  sagemaker_session=sagemaker_session,\n",
    "                                                  serializer=sagemaker.serializers.CSVSerializer(),\n",
    "                                                  deserializer=sagemaker.deserializers.CSVDeserializer(),\n",
    "                                                 )\n",
    "    else:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait until the endpoint has the status InService\n",
    "waiter = sagemaker_session.sagemaker_client.get_waiter('endpoint_in_service')\n",
    "waiter.wait(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download failed: s3://sagemaker-us-east-1-644383320443/siemens-poc/conatiner-jobs/test/test_x.csv to ../../test_x.csv [Errno 28] No space left on device: '/home/sagemaker-user/siemens-poc/test_x.csv.aC0c4FdA'\n",
      "download failed: s3://sagemaker-us-east-1-644383320443/siemens-poc/conatiner-jobs/test/test_y.csv to ../../test_y.csv [Errno 28] No space left on device: '/home/sagemaker-user/siemens-poc/test_y.csv.Ae4B5AB1'\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp $test_s3_url/test_x.csv /home/sagemaker-user/siemens-poc/test_x.csv\n",
    "!aws s3 cp $test_s3_url/test_y.csv /home/sagemaker-user/siemens-poc/test_y.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-644383320443/siemens-poc/conatiner-jobs/test'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_s3_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>22</th>\n",
       "      <th>1.1</th>\n",
       "      <th>0</th>\n",
       "      <th>3</th>\n",
       "      <th>8.919999999999998</th>\n",
       "      <th>7.000999999999998</th>\n",
       "      <th>66.0</th>\n",
       "      <th>15.0013</th>\n",
       "      <th>1.2</th>\n",
       "      <th>4</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.0.1</th>\n",
       "      <th>0.0.2</th>\n",
       "      <th>1.0</th>\n",
       "      <th>0.0.3</th>\n",
       "      <th>0.0.4</th>\n",
       "      <th>0.0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.78</td>\n",
       "      <td>30.0020</td>\n",
       "      <td>70.0</td>\n",
       "      <td>11.0014</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.98</td>\n",
       "      <td>5.0012</td>\n",
       "      <td>81.0</td>\n",
       "      <td>19.0012</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.98</td>\n",
       "      <td>5.0012</td>\n",
       "      <td>87.0</td>\n",
       "      <td>19.0012</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  22  1.1  0  3  8.919999999999998  7.000999999999998  66.0  15.0013  1.2  \\\n",
       "0  3  11    1  1  3              26.78            30.0020  70.0  11.0014    0   \n",
       "1  2   9    1  1  2               7.98             5.0012  81.0  19.0012    0   \n",
       "2  1   1    1  0  1               7.98             5.0012  87.0  19.0012    0   \n",
       "\n",
       "   4  0.0  0.0.1  0.0.2  1.0  0.0.3  0.0.4  0.0.5  \n",
       "0  9  0.0    0.0    0.0  0.0    0.0    0.0    1.0  \n",
       "1  3  0.0    0.0    0.0  0.0    0.0    0.0    1.0  \n",
       "2  6  0.0    0.0    0.0  1.0    0.0    0.0    0.0  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_x = pd.read_csv(\"tmp/test_x.csv\", names=[f'{i}' for i in range(59)])\n",
    "# test_y = pd.read_csv(\"tmp/test_y.csv\", names=['y'])\n",
    "import io\n",
    "s3_client = boto3.client(\"s3\")\n",
    "bucket_name = config['s3-bucket']['bucket_name']\n",
    "file_key  = \"siemens-poc/conatiner-jobs/test/test_x.csv\"\n",
    "response = s3_client.get_object(Bucket=bucket_name, Key=file_key)\n",
    "file_content = response['Body'].read()\n",
    "test_x = pd.read_csv(io.BytesIO(file_content), encoding='utf-8')\n",
    "test_x.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>276</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   276\n",
       "0  145\n",
       "1   75\n",
       "2    9"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_key  = \"siemens-poc/conatiner-jobs/test/test_y.csv\"\n",
    "response = s3_client.get_object(Bucket=bucket_name, Key=file_key)\n",
    "file_content = response['Body'].read()\n",
    "test_y = pd.read_csv(io.BytesIO(file_content), encoding='utf-8')\n",
    "test_y.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.0410924 , 1.20082128, 1.48737872, ..., 1.27996016, 2.97838068,\n",
       "       0.22001582])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.array(predictor.predict(test_x.values), dtype=float).squeeze()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>1</th>\n",
       "      <th>22</th>\n",
       "      <th>1.1</th>\n",
       "      <th>0</th>\n",
       "      <th>3</th>\n",
       "      <th>8.919999999999998</th>\n",
       "      <th>7.000999999999998</th>\n",
       "      <th>66.0</th>\n",
       "      <th>15.0013</th>\n",
       "      <th>1.2</th>\n",
       "      <th>4</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.0.1</th>\n",
       "      <th>0.0.2</th>\n",
       "      <th>1.0</th>\n",
       "      <th>0.0.3</th>\n",
       "      <th>0.0.4</th>\n",
       "      <th>0.0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.041092</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.78</td>\n",
       "      <td>30.0020</td>\n",
       "      <td>70.0</td>\n",
       "      <td>11.0014</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.200821</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.98</td>\n",
       "      <td>5.0012</td>\n",
       "      <td>81.0</td>\n",
       "      <td>19.0012</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.487379</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.98</td>\n",
       "      <td>5.0012</td>\n",
       "      <td>87.0</td>\n",
       "      <td>19.0012</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.243681</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22.08</td>\n",
       "      <td>24.0026</td>\n",
       "      <td>65.0</td>\n",
       "      <td>7.0015</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.880763</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>24.90</td>\n",
       "      <td>26.9990</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_pred  1  22  1.1  0  3  8.919999999999998  7.000999999999998  66.0  \\\n",
       "0  3.041092  3  11    1  1  3              26.78            30.0020  70.0   \n",
       "1  1.200821  2   9    1  1  2               7.98             5.0012  81.0   \n",
       "2  1.487379  1   1    1  0  1               7.98             5.0012  87.0   \n",
       "3  3.243681  3  12    1  1  3              22.08            24.0026  65.0   \n",
       "4  2.880763  3  10    1  1  3              24.90            26.9990  65.0   \n",
       "\n",
       "   15.0013  1.2   4  0.0  0.0.1  0.0.2  1.0  0.0.3  0.0.4  0.0.5  \n",
       "0  11.0014    0   9  0.0    0.0    0.0  0.0    0.0    0.0    1.0  \n",
       "1  19.0012    0   3  0.0    0.0    0.0  0.0    0.0    0.0    1.0  \n",
       "2  19.0012    0   6  0.0    0.0    0.0  1.0    0.0    0.0    0.0  \n",
       "3   7.0015    0  10  1.0    0.0    0.0  0.0    0.0    0.0    0.0  \n",
       "4   0.0000    0   9  0.0    1.0    0.0  0.0    0.0    0.0    0.0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate predictions \n",
    "test_results = pd.concat(\n",
    "    [\n",
    "        pd.Series(predictions, name=\"y_pred\", index=test_x.index),\n",
    "        test_x,\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "test_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predictions</th>\n",
       "      <th>-1.0</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actuals</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>547 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "predictions  -1.0   0.0   1.0   2.0   3.0   4.0\n",
       "actuals                                        \n",
       "1               1    10     5     3     1     0\n",
       "2               0     6     7     9     4     0\n",
       "3               0     9    12     5     1     1\n",
       "4               0     5     4     5     6     1\n",
       "5               0     9     9     9     7     2\n",
       "...           ...   ...   ...   ...   ...   ...\n",
       "871             0     0     0     0     1     0\n",
       "878             0     0     0     0     1     0\n",
       "884             0     0     1     1     0     0\n",
       "888             0     0     1     0     0     0\n",
       "925             0     0     0     1     0     0\n",
       "\n",
       "[547 rows x 6 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(\n",
    "    index=test_y['276'].values,\n",
    "    columns=np.round(predictions), \n",
    "    rownames=['actuals'], \n",
    "    colnames=['predictions']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-rmse: 70439.67\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "test_rmse = mean_squared_error(test_y, test_results[\"y_pred\"])\n",
    "print(f\"Test-rmse: {test_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model prediction test -- evaluation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>weekday_Fri</th>\n",
       "      <th>weekday_Mon</th>\n",
       "      <th>weekday_Sat</th>\n",
       "      <th>weekday_Sun</th>\n",
       "      <th>weekday_Thu</th>\n",
       "      <th>weekday_Tue</th>\n",
       "      <th>weekday_Wed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8.92</td>\n",
       "      <td>7.0010</td>\n",
       "      <td>66.0</td>\n",
       "      <td>15.0013</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.78</td>\n",
       "      <td>30.0020</td>\n",
       "      <td>70.0</td>\n",
       "      <td>11.0014</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.98</td>\n",
       "      <td>5.0012</td>\n",
       "      <td>81.0</td>\n",
       "      <td>19.0012</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  hr  holiday  workingday  weathersit   temp    atemp   hum  \\\n",
       "0       1  22        1           0           3   8.92   7.0010  66.0   \n",
       "1       3  11        1           1           3  26.78  30.0020  70.0   \n",
       "2       2   9        1           1           2   7.98   5.0012  81.0   \n",
       "\n",
       "   windspeed  yr  mnth  weekday_Fri  weekday_Mon  weekday_Sat  weekday_Sun  \\\n",
       "0    15.0013   1     4          0.0          0.0          0.0          1.0   \n",
       "1    11.0014   0     9          0.0          0.0          0.0          0.0   \n",
       "2    19.0012   0     3          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   weekday_Thu  weekday_Tue  weekday_Wed  \n",
       "0          0.0          0.0          0.0  \n",
       "1          0.0          0.0          1.0  \n",
       "2          0.0          0.0          1.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# s3://sagemaker-us-east-1-644383320443/\n",
    "import io\n",
    "file_key  = \"siemens-poc/pipeline-jobs/test/test_x.csv\"\n",
    "s3_client = boto3.client(\"s3\")\n",
    "response = s3_client.get_object(Bucket=config['s3-bucket']['bucket_name'], Key=file_key)\n",
    "file_content = response['Body'].read()\n",
    "X_test = pd.read_csv(io.BytesIO(file_content), encoding='utf-8')\n",
    "X_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cnt\n",
       "0  276\n",
       "1  145\n",
       "2   75"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_key  = \"siemens-poc/pipeline-jobs/test/test_y.csv\"\n",
    "response = s3_client.get_object(Bucket=config['s3-bucket']['bucket_name'], Key=file_key)\n",
    "file_content = response['Body'].read()\n",
    "y_test = pd.read_csv(io.BytesIO(file_content), encoding='utf-8')\n",
    "y_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_s3_path = 's3://sagemaker-us-east-1-644383320443/siemens-poc/training-output/xgboost-training-2024-01-15-19-27-29-687/output/model.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import tarfile\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from xgboost) (1.26.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from xgboost) (1.11.4)\n",
      "Downloading xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl (297.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.1/297.1 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stream and Load the Model Directly from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import io\n",
    "import tarfile\n",
    "import tempfile\n",
    "import xgboost as xgb\n",
    "\n",
    "bucket_name = config['s3-bucket']['bucket_name']\n",
    "model_file_key = 'siemens-poc/training-output/xgboost-training-2024-01-15-19-27-29-687/output/model.tar.gz'\n",
    "\n",
    "\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "model_file_stream = io.BytesIO()\n",
    "s3.Bucket(bucket_name).download_fileobj(model_file_key, model_file_stream)\n",
    "\n",
    "# Set the stream position to the start\n",
    "model_file_stream.seek(0)\n",
    "\n",
    "# Extract the model file from the tar.gz archive in memory\n",
    "with tarfile.open(fileobj=model_file_stream, mode=\"r:gz\") as tar:\n",
    "    # Extract the model file to a temporary file\n",
    "    with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\n",
    "        for member in tar.getmembers():\n",
    "            if member.name == 'xgboost-model':  # Adjust the file name as needed\n",
    "                tmp_file.write(tar.extractfile(member).read())\n",
    "                tmp_file.flush()\n",
    "                break\n",
    "\n",
    "# Load the XGBoost model from the temporary file\n",
    "model = xgb.Booster()\n",
    "model.load_model(tmp_file.name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xgboost.core.DMatrix object at 0x7f20897a5b10>\n",
      "[[276]\n",
      " [145]\n",
      " [ 75]\n",
      " ...\n",
      " [ 59]\n",
      " [335]\n",
      " [ 29]]\n"
     ]
    }
   ],
   "source": [
    "# Read test data\n",
    "# test_x = xgb.DMatrix(pd.read_csv(test_x_path).values)\n",
    "test_x = xgb.DMatrix(X_test.values)\n",
    "print(test_x)\n",
    "# test_y = pd.read_csv(test_y_path).to_numpy()\n",
    "test_y = y_test.to_numpy()\n",
    "print(test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.27996016 3.0410924  1.20082128 ... 1.27996016 2.97838068 0.22001582]\n"
     ]
    }
   ],
   "source": [
    "# Run predictions\n",
    "predictions = np.array(model.predict(test_x), dtype=float).squeeze()\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>season</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>weekday_Fri</th>\n",
       "      <th>weekday_Mon</th>\n",
       "      <th>weekday_Sat</th>\n",
       "      <th>weekday_Sun</th>\n",
       "      <th>weekday_Thu</th>\n",
       "      <th>weekday_Tue</th>\n",
       "      <th>weekday_Wed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.279960</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8.92</td>\n",
       "      <td>7.0010</td>\n",
       "      <td>66.0</td>\n",
       "      <td>15.0013</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.041092</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.78</td>\n",
       "      <td>30.0020</td>\n",
       "      <td>70.0</td>\n",
       "      <td>11.0014</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.200821</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.98</td>\n",
       "      <td>5.0012</td>\n",
       "      <td>81.0</td>\n",
       "      <td>19.0012</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.487379</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.98</td>\n",
       "      <td>5.0012</td>\n",
       "      <td>87.0</td>\n",
       "      <td>19.0012</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.243681</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22.08</td>\n",
       "      <td>24.0026</td>\n",
       "      <td>65.0</td>\n",
       "      <td>7.0015</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_pred  season  hr  holiday  workingday  weathersit   temp    atemp  \\\n",
       "0  1.279960       1  22        1           0           3   8.92   7.0010   \n",
       "1  3.041092       3  11        1           1           3  26.78  30.0020   \n",
       "2  1.200821       2   9        1           1           2   7.98   5.0012   \n",
       "3  1.487379       1   1        1           0           1   7.98   5.0012   \n",
       "4  3.243681       3  12        1           1           3  22.08  24.0026   \n",
       "\n",
       "    hum  windspeed  yr  mnth  weekday_Fri  weekday_Mon  weekday_Sat  \\\n",
       "0  66.0    15.0013   1     4          0.0          0.0          0.0   \n",
       "1  70.0    11.0014   0     9          0.0          0.0          0.0   \n",
       "2  81.0    19.0012   0     3          0.0          0.0          0.0   \n",
       "3  87.0    19.0012   0     6          0.0          0.0          0.0   \n",
       "4  65.0     7.0015   0    10          1.0          0.0          0.0   \n",
       "\n",
       "   weekday_Sun  weekday_Thu  weekday_Tue  weekday_Wed  \n",
       "0          1.0          0.0          0.0          0.0  \n",
       "1          0.0          0.0          0.0          1.0  \n",
       "2          0.0          0.0          0.0          1.0  \n",
       "3          1.0          0.0          0.0          0.0  \n",
       "4          0.0          0.0          0.0          0.0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate predictions\n",
    "test_results = pd.concat([pd.Series(predictions, name=\"y_pred\", index=X_test.index),X_test,],axis=1,)\n",
    "test_results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-rmse: 70442.56\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "test_rmse = mean_squared_error(test_y, test_results[\"y_pred\"])\n",
    "report_dict = {\"regression_metric\":{\"test_rmse\":{\"value\":test_rmse}}}\n",
    "print(f\"Test-rmse: {test_rmse:.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'regression_metric': {'test_rmse': {'value': 70442.56395592289}}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save evaluation report\n",
    "pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "with open(f\"{output_dir}/evaluation.json\", \"w\") as f:\n",
    "    f.write(json.dumps(report_dict))\n",
    "\n",
    "# Save prediction baseline file - we need it later for the model quality monitoring\n",
    "test_results.to_csv(os.path.join(output_prediction_path, 'prediction_baseline/prediction_baseline.csv'), index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-north-1:243637512696:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
